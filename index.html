<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MAIA">
  <meta name="keywords" content="Interpretability, LLMs, Multimodal, Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MAIA</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Multimodal Automated Interpretability Agent</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tamarott.github.io/">Tamar Rott Shaham</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://cogconfluence.com">Sarah Schwettmann</a><sup>*</sup>,</span>
		        <br>
            <span class="author-block">
              <a href="https://frankxwang.github.io/">Franklin Wang</a>,</span>
            <span class="author-block">
              <a href="https://twitter.com/AchyutaBot">Achyuta Rajaram</a>,</span>
            <span class="author-block">
              <a href="https://evandez.com/">Evan Hernandez</a>,</span>
            <span class="author-block">
              <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>,</span>
            <span class="author-block">
              <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a>
            </span>
          </div>
		
	  * indicates equal contribution.

          <div class="is-size-5 publication-authors">
            <span class="author-block">MIT CSAIL</span>
          </div> 

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2309.03886.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
		<a href="https://arxiv.org/abs/2309.03886"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
             	 </a>   
              </span>
              <!-- Code Link. -->
              <span class="link-block">
              	<a href="https://github.com/multimodal-interpretability/FIND" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
              	</a>  
              </span>
            
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="margin-top: -10px; margin-bottom:-10px">
    <div class="container is-max-desktop">
        <div style="text-align: justify;">
            <p>Understanding an AI system can take many forms. For instance, we might want to know when and how the system relies on sensitive or spurious features, identify systematic errors in its predictions, or learn how to modify the training data and model architecture to improve accuracy and robustness. Today, answering these types of questions often involves significant effort on the part of researchers: synthesizing the outcomes of different experiments that use a variety of tools.</p><br>
	    <p><h3 class="title is-4">Can an interpretability agent automate this process of experimenting on a system to explain its behavhior?</h3></p>
	</div>
    </div>
</section>
	
<section class="hero teaser" style="margin-top: -5px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <div style="display: flex; justify-content: center; width: 100%;">
            <img src="./static/figures/teaser.gif" style="width: 95%; height: auto;" />
        </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered">
      <div class="content">
        <h2 class="title is-3 has-text-centered">MAIA</h2>
        <div style="display: flex; align-items: center;">
          <img src="./static/figures/MAIA_schematic.png" alt="MAIA Schematic" style="margin-right: 20px; width: 40%;">
          <p style="text-align: justify;">
            We describe MAIA, a Multimodal Automated Interpretability Agent. MAIA is a system that uses neural models to automate neural model understanding tasks like feature interpretation and failure mode discovery.
            It equips a pre-trained vision-language model with a set of tools that support iterative experimentation on subcomponents of other models to explain their behavior. These include tools commonly used by human interpretability researchers: for synthesizing and editing inputs, computing maximally activating exemplars from real-world datasets, and summarizing and describing experimental results.
            <i>Interpretability experiments</i> proposed by MAIA compose these tools to describe and explain system behavior.
          </p>
        </div>
        <hr>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="hero teaser" style="margin-top: -5px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">MAIA Tools</h2>
      <div class="content" style="text-align: left;">
        <p>MAIA composes interpretability subroutines into python programs to answer user queries about a system. What kind of experiments does MAIA design? Below we highlight example usage of individual tools to run experiments on neurons inside common vision architectures (CLIP, ResNet, DINO). These are experimental excerpts intended to demonstrate tool use (often, MAIA runs many more experiments to reach its final conclusion!) For full experiment logs, check out our interactive [neuron viewer]. </p>
      </div>
      
      <h3 class="subtitle is-5" style="text-align: left;">Visualizing Dataset Exemplars</h3>
      <p>MAIA uses the <code>dataset_exemplars</code> tool to compute images from the ImageNet dataset that maixmally activate a given system (in this case, an individual neuron). The <code>dataset_exemplars</code> tool returns masked versions of the images highlighting <i>image subregions</i> that maximally activate the neuron, as well as the activation value.</p><br>
      
      <div style="display: flex; justify-content: center; width: 100%;">
        <img src="./static/figures/dataset_exemplars_gif.gif" alt="Dataset Exemplars" style="width: 95%; height: auto;" />
      </div>
      
      <h3 class="subtitle is-5" style="text-align: left;">Generating Synthetic Test Images</h3>
      <p>In addition to using real-world stimuli as inputs to the system it is trying to interpret, MAIA can generate additional synthetic inputs that test specific dimensions of a system's selectivity. MAIA uses the <code>text_to_image</code> function to call a pretrained text-guided diffusion model on prompts it writes. These prompts can test specific hypotheses about the neuron's selectivities, such as in the example of the tennis ball neuron below.</p><br>

      <div style="display: flex; justify-content: center; width: 100%; "margin-top: 5px;">
        <img src="./static/figures/synthetic_exemplars_gif.gif" alt="Synthetic Exemplars" style="width: 95%; height: auto;" />
      </div>
	    
      <h3 class="subtitle is-5" style="text-align: left;">Image editing</h3>
      <p>Maia can also call the <code>edit_images</code> tool which uses an text-based image editing module (Instruct Pix2Pix) to make image edits according to prompts written by MAIA. MAIA uses this tool to causally intervene on input space in order to test specific hypotheses about system behavior (e.g. whether the presence of a certain feature is required for the observed behavior!)</p><br>

      <div style="display: flex; justify-content: center; width: 100%; "margin-top: 5px;">
        <img src="./static/figures/editing_images_gif.gif" alt="Synthetic Exemplars" style="width: 95%; height: auto;" />
      </div>
	    
    </div>
  </div>
</section>
	
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{%%%%,
      title={A Multimodal Automated Interpretability Agent},
      author={Rott Shaham, Tamar and Schwettmann, Sarah and Wang, Franklin and Rajaram, Achyuta and Hernandez, Evan and Andreas, Jacob and Torralba, Antonio},
      booktitle={TBD Arxiv},
      year={2024}
    }
    </code></pre>
  </div>
</section>

	
<footer class="footer">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content" style="text-align: center;">
        <p>
          This website is adapted from the <a href="https://github.com/nerfies/nerfies.github.io" class="footer-link">Nerfies template</a>, which you are free to borrow if you link back to it in the footer.
        </p>
      </div>
    </div>
  </div>
</div>
</footer>


</body>
</html>
